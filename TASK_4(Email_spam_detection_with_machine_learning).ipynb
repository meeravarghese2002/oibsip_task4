{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MJ0LTywPJUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff48dc1-32f0-4192-d9c7-5b89eea955d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading of csv file\n",
        "df = pd.read_csv('spam.csv',encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "FEPA-u2KtIax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying dataset\n",
        "print(\"Email spam detection dataset is: \\n\",df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHWJhBSntZe8",
        "outputId": "28716903-f7ee-409c-c566-b54fcceed9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email spam detection dataset is: \n",
            "         v1                                                 v2 Unnamed: 2  \\\n",
            "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "...    ...                                                ...        ...   \n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
            "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
            "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
            "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
            "5571   ham                         Rofl. Its true to its name        NaN   \n",
            "\n",
            "     Unnamed: 3 Unnamed: 4  \n",
            "0           NaN        NaN  \n",
            "1           NaN        NaN  \n",
            "2           NaN        NaN  \n",
            "3           NaN        NaN  \n",
            "4           NaN        NaN  \n",
            "...         ...        ...  \n",
            "5567        NaN        NaN  \n",
            "5568        NaN        NaN  \n",
            "5569        NaN        NaN  \n",
            "5570        NaN        NaN  \n",
            "5571        NaN        NaN  \n",
            "\n",
            "[5572 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Top and Botton 5 rows of car price prediction dataset\n",
        "print(\"Top 5 rows of the dataset are: \\n\",df.head())\n",
        "print(\"\\n\\nBottom 5 rows of the dataset are: \\n\",df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdbJouNutfA0",
        "outputId": "930a7af5-f402-4dae-9b16-f63efd7d88ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 rows of the dataset are: \n",
            "      v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "\n",
            "\n",
            "Bottom 5 rows of the dataset are: \n",
            "         v1                                                 v2 Unnamed: 2  \\\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
            "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
            "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
            "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
            "5571   ham                         Rofl. Its true to its name        NaN   \n",
            "\n",
            "     Unnamed: 3 Unnamed: 4  \n",
            "5567        NaN        NaN  \n",
            "5568        NaN        NaN  \n",
            "5569        NaN        NaN  \n",
            "5570        NaN        NaN  \n",
            "5571        NaN        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps=PorterStemmer()\n",
        "lemmatize=WordNetLemmatizer()\n",
        "corpus=[]\n",
        "for i in range(0,len(df)):\n",
        "  review=re.sub('[^a-zA-Z]', ' ', df['v2'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "    \n",
        "  review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "VZ5aZCEKtlI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y=pd.get_dummies(df['v1'])\n",
        "y=y.iloc[:,1].values"
      ],
      "metadata": {
        "id": "C9fN99z1tvVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "S44hY9n8t7Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)  "
      ],
      "metadata": {
        "id": "Xe91tWyPuAdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1mL7R-JfuIpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=spam_detect_model.predict(X_test)"
      ],
      "metadata": {
        "id": "VfurKLlduMMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model precision:\n",
        "\n",
        "The model precision score measures the proportion of positively predicted labels that are actually correct. Precision is also known as the positive predictive value. Precision is used in conjunction with the recall to trade-off false positives and false negatives. Precision is affected by the class distribution. **Precision Score = TP / (FP + TP)\n",
        "\n",
        "Accuracy Score:\n",
        "\n",
        "Model recall score represents the model’s ability to correctly predict the positives out of actual positives. This is unlike precision which measures how many predictions made by models are actually positive out of all positive predictions made. **Recall Score = TP / (FN + TP)\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "A confusion matrix, also referred to as an error matrix, is a process that helps to assess and predict the validity of a classification model. Using confusion matrices allows you to see different errors which you could make when you make predictions.\n",
        "\n",
        "Classification Report\n",
        "\n",
        "A classification report is a performance evaluation metric in machine learning. It is used to show the precision, recall, F1 Score, and support of your trained classification model."
      ],
      "metadata": {
        "id": "Z0ovnLPduR9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6kRB-nduXeC",
        "outputId": "d68f8964-3a76-4553-8f88-4de86b42826d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[943   6]\n",
            " [  9 157]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2dPkjXuuhqj",
        "outputId": "b4306be2-b15b-4854-a734-3464bc23366c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score 0.9865470852017937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK8Q3KJ1ul-U",
        "outputId": "706065cf-faf9-4d65-8969-cdfad6c4aae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       949\n",
            "           1       0.96      0.95      0.95       166\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.98      0.97      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}